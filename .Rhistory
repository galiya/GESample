corpus <- tm_map(corpus, stemCompletion, dictionary = dictCorpus)
corpus[[1]]
corpus[1]
docMatrix <- TermDocumentMatrix(corpus, control = list(minWordLength = 1))
docMatrix <- TermDocumentMatrix(corpus)
corpus <- tm_map(corpus, stemDocument, lazy = TRUE)
docMatrix <- TermDocumentMatrix(corpus, control = list(minWordLength = 1))
?TermDocumentMatrix
corpus <- Corpus(VectorSource(tweetsText), readerControl = list(language = "en"))
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, content_transformer(removeNumbers))
corpus <- tm_map(corpus, content_transformer(removePunctuation)) #can be modified to preserve #
corpus <- tm_map(corpus, removeWords, stopwords("english"))
dictCorpus <- corpus
corpus <- tm_map(corpus, stemDocument, lazy = TRUE)
corpus[[1]]
corpus <- tm_map(corpus, stemCompletion, dictionary = dictCorpus)
corpus[[1]]
corpus <- Corpus(VectorSource(tweetsText), readerControl = list(language = "en"))
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, content_transformer(removeNumbers))
corpus <- tm_map(corpus, content_transformer(removePunctuation)) #can be modified to preserve #
corpus <- tm_map(corpus, removeWords, stopwords("english"))
dictCorpus <- corpus
corpus <- tm_map(corpus, stemDocument, lazy = TRUE)
docMatrix <- TermDocumentMatrix(yCorpus, control = list(minWordLength = 1))
docMatrix <- TermDocumentMatrix(corpus, control = list(minWordLength = 1))
docMatrix
docMatrix[[1]]
corpuscopy <- corpus
corpus <- Corpus(VectorSource(tweetsText), readerControl = list(language = "en"))
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, content_transformer(removeNumbers))
corpus <- tm_map(corpus, content_transformer(removePunctuation)) #can be modified to preserve #
corpus <- tm_map(corpus, removeWords, stopwords("english"))
corpuscopy <- corpus
corpus <- tm_map(corpus, stemDocument, lazy = TRUE)
stemCompletion_mod <- function(x,dict=corpuscopy) {
PlainTextDocument(stripWhitespace(paste(stemCompletion(unlist(strsplit(as.character(x)," ")),dictionary=dict, type="shortest"),sep="", collapse=" ")))
}
lapply(corpus, stemCompletion_mod)
tweetsText[32]
corpus <- Corpus(VectorSource(tweetsText), readerControl = list(language = "en"))
corpus <- tm_map(corpus, content_transformer(tolower))
#corpus <- tm_map(corpus, content_transformer(removeNumbers))
corpus <- tm_map(corpus, content_transformer(removePunctuation)) #can be modified to preserve #
corpus <- tm_map(corpus, removeWords, stopwords("english"))
corpuscopy <- corpus
corpus <- tm_map(corpus, stemDocument, lazy = TRUE)
stemCompletion_mod <- function(x,dict=corpuscopy) {
PlainTextDocument(stripWhitespace(paste(stemCompletion(unlist(strsplit(as.character(x)," ")),dictionary=dict, type="shortest"),sep="", collapse=" ")))
}
lapply(corpus, stemCompletion_mod)
tweetsText[31]
corpuscopy
corpuscopy[1]
corpuscopy[[1]]
corpus <- Corpus(VectorSource(tweetsText), readerControl = list(language = "en"))
corpus <- tm_map(corpus, content_transformer(tolower))
#corpus <- tm_map(corpus, content_transformer(removeNumbers))
corpus <- tm_map(corpus, content_transformer(removePunctuation)) #can be modified to preserve #
corpus <- tm_map(corpus, removeWords, stopwords("english"))
corpuscopy <- corpus
corpus <- tm_map(corpus, stemDocument)
corpus[[1]]
corpus[[3]]
corpus[[4]]
corpus1 <- tm_map(corpus, stemCompletion, dictionary = corpuscopy)
corpus1[[4]]
stemCompletion_mod <- function(x,dict=corpuscopy) {
PlainTextDocument(stripWhitespace(paste(stemCompletion(unlist(strsplit(as.character(x)," ")),dictionary=dict, type="shortest"),sep="", collapse=" ")))
}
corpus1 <- lapply(corpus, stemCompletion_mod)
corpus1[[4]]
corpus <- Corpus(VectorSource(tweetsText), readerControl = list(language = "en"))
corpus <- tm_map(corpus, content_transformer(tolower))
#corpus <- tm_map(corpus, content_transformer(removeNumbers))
corpus <- tm_map(corpus, removePunctuation) #can be modified to preserve #
corpus <- tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, removeWords, stopwords("english"))
corpuscopy <- corpus
corpus <- tm_map(corpus, stemDocument)
stemCompletion_mod <- function(x,dict=corpuscopy) {
PlainTextDocument(paste(stemCompletion(unlist(strsplit(as.character(x)," ")),dictionary=dict, type="shortest"),sep="", collapse=" "))}
corpus1 <- lapply(corpus, stemCompletion_mod)
corpuscopy[[1]]
corpuscopy[[4]]
corpus1[[4]]
corpus[[4]]
lapply(corpus, stemCompletion_mod)
dictCorpus[1]
dictCorpus[2]
dictCorpus[[1]]
dictCorpus[[2]]
dictCorpus[[3:33]]
dictCorpus[[3:32]]
dictCorpus[[4]]
corpus <- Corpus(VectorSource(tweetsText), readerControl = list(language = "en"))
corpus <- tm_map(corpus, content_transformer(tolower))
#corpus <- tm_map(corpus, content_transformer(removeNumbers))
corpus <- tm_map(corpus, removePunctuation) #can be modified to preserve #
corpus <- tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, removeWords, stopwords("english"))
docMatrix <- TermDocumentMatrix(corpus, control = list(minWordLength = 1))
docMatrix[[1]]
docMatrix
findFreqTerms(docMatrix, lowfreq=30)
findFreqTerms(docMatrix, lowfreq=50)
tweets.dtm
tweets.dtm <- TermDocumentMatrix(corpus, control = list(minWordLength = 1))
findAssocs(tweets.dtm, 'ge', 0.20)
findAssocs(tweets.dtm, 'polish', 0.20)
findAssocs(tweets.dtm, 'snp', 0.20)
findAssocs(tweets.dtm, 'labour', 0.20)
labourAssocs <- findAssocs(tweets.dtm, 'labour', 0.20)
findAssocs(tweets.dtm, 'tory', 0.20)
findAssocs(tweets.dtm, 'snp', 0.20)
findAssocs(tweets.dtm, 'general', 0.20)
findAssocs(tweets.dtm, 'ukip', 0.20)
seatsAssocs <- findAssocs(tweets.dtm, 'seats', 0.20)
findAssocs(tweets.dtm, 'seats', 0.20)
labourAssocs <- findAssocs(tweets.dtm, 'labour', 0.20)
snpAssocs <- findAssocs(tweets.dtm, 'snp', 0.20)
ukipAssocs <- findAssocs(tweets.dtm, 'ukip', 0.20)
jsonfile <- readRDS("data/tweets.rds")
ls
dir()
setwd("GESample/")
jsonfile <- readRDS("data/tweets.rds")
jsonfile <- "data/tweets.txt"
data <- fromJSON(sprintf("[%s]", paste(readLines(jsonfile), collapse=",")))
tweetsText <- data$text
?memoise
install.packages("memoise")
library(memoise)
?memoise
library(shinyapps)
shinyapps::deployApp('GESample/')
setwd("~/Projects/GESample/")
shinyapps::deployApp('GESample/')
shinyapps::deployApp('GESample/')
shinyapps::deployApp('GESample/')
shinyapps::deployApp('GESample/')
install.packages("shinyIncubator")
shinyapps::deployApp('GESample/')
devtools::install_github("shiny-incubator", "rstudio")
library(shinyIncubator)
shinyapps::deployApp('GESample/')
assocsChoices <- c('labour', 'snp', 'ukip')
library(rCharts)
library(wordcloud)
install.packages("wordcloud")
library(wordcloud)
jsonfile <- "data/Tweets.txt"
data <- fromJSON(sprintf("[%s]", paste(readLines(jsonfile), collapse=",")))
tweetsText <- data$text
getTermMatrix <- memoise(function() {
#remove urls
tweetsText <- gsub("http.*$", "", gsub('http.*\\s', ' ', tweetsText))
#remove RTs
tweetsText <- gsub('(RT|via)((?:\\b\\W*@\\w+)+):', '', tweetsText)
# remove blank spaces at the beginning
tweetsText <- gsub("^ ", "", tweetsText)
# remove blank spaces at the end
tweetsText <- gsub(" $", "", tweetsText)
# remove control chars
tweetsText <- gsub("[[:cntrl:]]", "", tweetsText)
corpus <- Corpus(VectorSource(tweetsText), readerControl = list(language = "en"))
corpus <- tm_map(corpus, content_transformer(tolower))
#corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, removePunctuation) #can be modified to preserve #
corpus <- tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, removeWords, stopwords("english"))
#tweets.dtm <-
TermDocumentMatrix(corpus, control = list(minWordLength = 1))
})
tweets.dtm <- getTermMatrix()
labourAssocs <- findAssocs(tweets.dtm, 'labour', 0.20)
labourAssocs
names(labourAssocs) <- c("term", "assoc")
labourAssocs
labourAssocs <- findAssocs(tweets.dtm, 'labour', 0.20)
labourAssocs
labourAssocs[1]
labourAssocs[2]
?findAssocs
labourAssocs$terms
labourAssocs["snp"]
tweets.matrix <- as.matrix(tweets.dtm)
word.freq <- sort(rowSums(tweets.matrix), decreasing = TRUE)
wordcloud(words = names(word.freq), freq = word.freq, min.freq = 3, random.order = FALSE)
word.freq
names(word.freq)
names(labourAssocs)
wordcloud(words = names(word.freq), freq = word.freq, min.freq = 3, random.order = FALSE, random.color = TRUE)
wordcloud(words = names(word.freq), freq = word.freq, min.freq = 3, random.order = FALSE, random.color = TRUE)
wordcloud(words = names(word.freq), freq = word.freq, min.freq = 3, random.order = FALSE, random.color = TRUE)
wordcloud(words = names(word.freq), freq = word.freq, min.freq = 3, random.order = FALSE, random.color = TRUE)
wordcloud(words = names(word.freq), freq = word.freq, min.freq = 3, random.order = FALSE, random.color = TRUE)
wordcloud(words = names(word.freq), freq = word.freq, min.freq = 5, random.order = FALSE, random.color = TRUE)
wordcloud(words = names(word.freq), freq = word.freq, min.freq = 4, random.order = FALSE, random.color = TRUE)
wordcloud(words = names(word.freq), freq = word.freq, min.freq = 5, random.order = FALSE, random.color = TRUE)
wordcloud(words = names(word.freq), freq = word.freq, min.freq = 3, random.order = FALSE, random.color = TRUE)
wordcloud(words = names(word.freq), freq = word.freq, min.freq = 3, random.order = FALSE, random.color = TRUE)
wordcloud(words = names(word.freq), freq = word.freq, min.freq = 3, random.order = FALSE, random.color = TRUE)
names(labourAssocs)
labourAssocs
as.matrix(labourAssocs)
as.matrix(labourAssocs)[1]
as.matrix(labourAssocs)["mps"]
dim(tweets.dtm)
tweets.dtm.sparse <- removeSparseTerms(tweets.dtm, 0.1)
dim(tweets.dtm.sparse)
tweets.dtm.sparse <- removeSparseTerms(tweets.dtm, 0.05)
dim(tweets.dtm.sparse)
inspect(tweets.dtm.sparse)
labourAssocs[1:20]
tweets.matrix <- as.matrix(tweets.dtm)
set.seed(100)
word.freq <- sort(rowSums(tweets.matrix), decreasing = TRUE)
wordcloud(words = names(word.freq), freq = word.freq, min.freq = 3, random.order = FALSE, random.color = TRUE)
wordcloud(words = names(word.freq), freq = word.freq, min.freq = 3, random.order = FALSE, random.color = TRUE)
set.seed(100)
word.freq <- sort(rowSums(tweets.matrix), decreasing = TRUE)
wordcloud(words = names(word.freq), freq = word.freq, min.freq = 3, random.order = FALSE, random.color = TRUE)
set.seed(100)
word.freq <- sort(rowSums(tweets.matrix), decreasing = TRUE)
wordcloud(words = names(word.freq), freq = word.freq, min.freq = 3, random.order = FALSE, random.color = TRUE)
set.seed(100)
word.freq <- sort(rowSums(tweets.matrix), decreasing = TRUE)
wordcloud(words = names(word.freq), freq = word.freq, min.freq = 3, random.order = FALSE, random.color = TRUE)
set.seed(100) #to ensure the wordcloud has the same layout
word.freq <- sort(rowSums(tweets.matrix), decreasing = TRUE)
wordcloud(words = names(word.freq), freq = word.freq, min.freq = 3, colors=brewer.pal(6, "Dark2")))
set.seed(100) #to ensure the wordcloud has the same layout
word.freq <- sort(rowSums(tweets.matrix), decreasing = TRUE)
wordcloud(words = names(word.freq), freq = word.freq, min.freq = 3, colors=brewer.pal(6, "Dark2"))
set.seed(100) #to ensure the wordcloud has the same layout
word.freq <- sort(rowSums(tweets.matrix), decreasing = TRUE)
wordcloud(words = names(word.freq), freq = word.freq, min.freq = 3, colors=brewer.pal(6, "Dark2"))
set.seed(100) #to ensure the wordcloud has the same layout
word.freq <- sort(rowSums(tweets.matrix), decreasing = TRUE)
wordcloud(words = names(word.freq), freq = word.freq, min.freq = 3, colors=brewer.pal(6, "Dark2"))
set.seed(100) #to ensure the wordcloud has the same layout
word.freq <- sort(rowSums(tweets.matrix), decreasing = TRUE)
wordcloud(words = names(word.freq), freq = word.freq, min.freq = 3, rot.per=0.2, colors=dark2)
set.seed(100) #to ensure the wordcloud has the same layout
word.freq <- sort(rowSums(tweets.matrix), decreasing = TRUE)
wordcloud(words = names(word.freq), freq = word.freq, min.freq = 3, rot.per=0.2, colors=brewer.pal(6, "Dark2"))
findAssocs
labourAssocs <- findAssocs(tweets.dtm, c('labour'), c(0.25))
labourAssocs
labourAssocs["back"]
labourAssocs("back")
class(labourAssocs)
labourAssocs[1,]
labourAssocs[1,1]
labourAssocs[,1]
as.list(labourAssocs[,1])
x <- as.list(labourAssocs[,1])
x[1]
names(x)
labourAssocs <- findAssocs(tweets.dtm, 'labour', 0.25)
labourAssocs[,1]
names(labourAssocs[,1])
labourAssocs.list <- labourAssocs[,1]
word.freq <- sort(rowSums(labourAssocs.list), decreasing = TRUE)
word.freq <- sort(rowSums(labourAssocs), decreasing = TRUE)
word.freq
wordcloud(words = names(word.freq), freq = word.freq, min.freq = 3, rot.per=0.2, colors=brewer.pal(6, "Dark2"))
labourAssocs <- findAssocs(tweets.dtm, 'labour', 0.45)
snpAssocs <- findAssocs(tweets.dtm, 'snp', 0.45)
ukipAssocs <- findAssocs(tweets.dtm, 'ukip', 0.45)
tweets.matrix <- as.matrix(tweets.dtm)
set.seed(100) #to ensure the wordcloud has the same layout
word.freq <- sort(rowSums(tweets.matrix), decreasing = TRUE)
wordcloud(words = names(word.freq), freq = word.freq, min.freq = 3, rot.per=0.2, colors=brewer.pal(6, "Dark2"))
snpAssocs
ukipAssocs
snpAssocs <- findAssocs(tweets.dtm, 'snp', 0.2)
snpAssocs
ukipAssocs <- findAssocs(tweets.dtm, 'ukip', 0.2)
ukipAssocs
getTermMatrix <- memoise(function() {
#remove urls
tweetsText <- gsub("http.*$", "", gsub('http.*\\s', ' ', tweetsText))
#remove RTs
tweetsText <- gsub('(RT|via)((?:\\b\\W*@\\w+)+):', '', tweetsText)
# remove blank spaces at the beginning
tweetsText <- gsub("^ ", "", tweetsText)
# remove blank spaces at the end
tweetsText <- gsub(" $", "", tweetsText)
# remove control chars
tweetsText <- gsub("[[:cntrl:]]", "", tweetsText)
corpus <- Corpus(VectorSource(tweetsText), readerControl = list(language = "en"))
corpus <- tm_map(corpus, content_transformer(tolower))
#corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, removePunctuation) #can be modified to preserve #
corpus <- tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, removeWords, c(stopwords("english"), "general", "election", "ge15", "ge2015", "2015"))
#tweets.dtm <-
TermDocumentMatrix(corpus, control = list(minWordLength = 1))
})
tweets.dtm <- getTermMatrix()
tweets.matrix <- as.matrix(tweets.dtm)
set.seed(100) #to ensure the wordcloud has the same layout
word.freq <- sort(rowSums(tweets.matrix), decreasing = TRUE)
wordcloud(words = names(word.freq), freq = word.freq, min.freq = 3, rot.per=0.2, colors=brewer.pal(6, "Dark2"))
labourAssocs <- findAssocs(tweets.dtm, 'labour', 0.2)
snpAssocs <- findAssocs(tweets.dtm, 'snp', 0.2)
ukipAssocs <- findAssocs(tweets.dtm, 'ukip', 0.2)
snpAssocs
ukipAssocs
labourAssocs
labourAssocs <- findAssocs(tweets.dtm, 'labour', 0.4)
labourAssocs
?rPlot
labourAssocs.freq <- sort(rowSums(labourAssocs), decreasing = TRUE)
labourAssocs.freq
rPlot(names(labourAssocs.freq) ~ labourAssocs.freq)
rPlot(names(labourAssocs.freq) ~ labourAssocs.freq, data=labourAssocs.freq)
labourAssocs.freq
class(labourAssocs.freq)
labourAssocs.freq <- sort(rowSums(labourAssocs), decreasing = TRUE)
labourAssocs.df <- data.frame(word = names(labourAssocs.freq), freq=labourAssocs.freq)
rPlot(word ~ freq, data=labourAssocs.df)
rPlot(word ~ freq, data=labourAssocs.df, type = 'bar')
ggplot(aes(word, freq))
labourAssocs.df
library(ggplot2)
install.packages("ggplot2")
library(ggplot2)
ggplot(aes(word, freq))
ggplot(aes(word, freq), data=labourAssocs.df)
p <- ggplot(aes(word, freq), data=labourAssocs.df)
p <- p + geom_line()
p
barplot(labourAssocs.df)
qplot(x=word, y=freq, data=labourAssocs.df, geom="bar", stat="identity", position="dodge")
rPlot(x = word, y = freq, data=labourAssocs.df, type = 'bar')
rPlot(x = "word", y = "freq", data=labourAssocs.df, type = 'bar')
p1 <- rPlot(x = list(var = "word", sort = "freq"), y = "freq", data=labourAssocs.df, type = 'bar')
assocsTerm <- 'labour'
corLimit <- 0.4
termAssocs <- findAssocs(tweets.dtm, assocsTerm, corLimit)
termAssocs.freq <- sort(rowSums(termAssocs), decreasing = TRUE)
termAssocs.df <- data.frame(word = names(termAssocs.freq), freq=termAssocs.freq)
p1 <- rPlot(x = list(var = "word", sort = "freq"), y = "freq", data=termAssocs.df, type = 'bar')
p1
xTitle <- paste("Associations with term ", assocsTerm)
xTitle
xTitle <- paste("Associations with term", assocsTerm)
xTitle
xTitle <- paste("Associations with term'", assocsTerm, "'")
xTitle
xTitle <- paste("Associations with term '", assocsTerm, "'")
xTitle
xTitle <- cat("Associations with term '", assocsTerm, "'")
xTitle <- cat("Associations with term '",assocsTerm,"'")
xTitle <- cat("Associations with term '",assocsTerm,"'")
p1$guides(x = list(title = xTitle)
p1$guides(y = list(title = "Frequency", max = 18))
p1 <- rPlot(x = list(var = "word", sort = "freq"), y = "freq", data=termAssocs.df, type = 'bar')
p1
xTitle <- cat("Associations with term '",assocsTerm,"'")
p1$guides(x = list(title = xTitle))
p1$guides(y = list(title = "Frequency", max = 18))
p1
p1$guides(y = list(title = "Frequency", max = 1))
p1
p1$guides(x = list(title = assocsTerm))
p1
xTitle <- paste("Associations with term '",assocsTerm,"'")
p1$guides(x = list(title = xTitle))
p1
p1 <- rPlot(x = list(var = "word", sort = "freq"), y = "freq", data=termAssocs.df, type = 'bar')
chartTitle <- paste("Associations with term '",assocsTerm,"'")
p1$guides(x = list(title = ""))
p1$guides(y = list(title = "Frequency", max = 1))
# Step 5. set the width and height of the plot and attach it to the dom
p1$addParams(width = 600, height = 300, dom = 'chart1',
title = chartTitle)
p1
assocsTerm <- 'ukip'
corLimit <- 0.2
termAssocs <- findAssocs(tweets.dtm, assocsTerm, corLimit)
#snpAssocs <- findAssocs(tweets.dtm, 'snp', 0.2)
#ukipAssocs <- findAssocs(tweets.dtm, 'ukip', 0.2)
termAssocs.freq <- sort(rowSums(termAssocs), decreasing = TRUE)
termAssocs.df <- data.frame(word = names(termAssocs.freq), freq=termAssocs.freq)
require(rCharts)
p1 <- rPlot(x = list(var = "word", sort = "freq"), y = "freq", data=termAssocs.df, type = 'bar')
chartTitle <- paste("Associations with term '",assocsTerm,"'")
p1$guides(x = list(title = ""))
p1$guides(y = list(title = "Frequency", max = 1))
# Step 5. set the width and height of the plot and attach it to the dom
p1$addParams(width = 600, height = 300, dom = 'chart1',
title = chartTitle)
# Step 6. print the chart (just type p1 if you are using it in your R console)
p1
assocsTerm <- 'ukip'
corLimit <- 0.2
termAssocs <- findAssocs(tweets.dtm, assocsTerm, corLimit)
#snpAssocs <- findAssocs(tweets.dtm, 'snp', 0.2)
#ukipAssocs <- findAssocs(tweets.dtm, 'ukip', 0.2)
termAssocs.freq <- sort(rowSums(termAssocs), decreasing = TRUE)
termAssocs.df <- data.frame(word = names(termAssocs.freq), freq=termAssocs.freq)
require(rCharts)
p1 <- rPlot(x = list(var = "word", sort = "freq"), y = "freq", data=termAssocs.df, type = 'bar')
chartTitle <- paste("Associations with term '",assocsTerm,"'")
p1$guides(x = list(title = ""))
p1$guides(y = list(title = "Frequency", max = 1.1))
# Step 5. set the width and height of the plot and attach it to the dom
p1$addParams(width = 600, height = 300, dom = 'chart1',
title = chartTitle)
# Step 6. print the chart (just type p1 if you are using it in your R console)
p1 #$print()
assocsTerm <- 'snp'
corLimit <- 0.2
termAssocs <- findAssocs(tweets.dtm, assocsTerm, corLimit)
#snpAssocs <- findAssocs(tweets.dtm, 'snp', 0.2)
#ukipAssocs <- findAssocs(tweets.dtm, 'ukip', 0.2)
termAssocs.freq <- sort(rowSums(termAssocs), decreasing = TRUE)
termAssocs.df <- data.frame(word = names(termAssocs.freq), freq=termAssocs.freq)
require(rCharts)
p1 <- rPlot(x = list(var = "word", sort = "freq"), y = "freq", data=termAssocs.df, type = 'bar')
chartTitle <- paste("Associations with term '",assocsTerm,"'")
p1$guides(x = list(title = ""))
p1$guides(y = list(title = "Frequency", max = 1.1))
# Step 5. set the width and height of the plot and attach it to the dom
p1$addParams(width = 600, height = 300, dom = 'chart1',
title = chartTitle)
# Step 6. print the chart (just type p1 if you are using it in your R console)
p1 #$print()
shinyapps::deployApp('GESample/')
shinyapps::deployApp('GESample/')
shinyapps::deployApp('GESample/')
shinyapps::deployApp('GESample/')
shinyapps::deployApp('GESample/')
shinyapps::deployApp('GESample/')
shinyapps::deployApp('GESample/')
shinyapps::deployApp('GESample/')
shinyapps::deployApp('GESample/')
shinyapps::deployApp('GESample/')
shinyapps::deployApp('GESample/')
shinyapps::deployApp('GESample/')
shinyapps::deployApp('GESample/')
shinyapps::deployApp('GESample/')
shinyapps::deployApp('GESample/')
shinyapps::deployApp('GESample/')
shinyapps::deployApp('GESample/')
shinyapps::deployApp('GESample/')
shinyapps::deployApp('GESample/')
shinyapps::deployApp('GESample/')
shinyapps::deployApp('GESample/')
shinyapps::deployApp('GESample/')
?shinyUI
shinyapps::deployApp('GESample/')
shinyapps::deployApp('GESample/')
shinyapps::deployApp('GESample/')
shinyapps::deployApp('GESample/')
shinyapps::deployApp('GESample/')
shinyapps::deployApp('GESample/')
shinyapps::deployApp('GESample/')
shinyapps::deployApp('GESample/')
shinyapps::deployApp('GESample/')
shinyapps::deployApp('GESample/')
shinyapps::deployApp('GESample/')
shinyapps::deployApp('GESample/')
shinyapps::deployApp('GESample/')
shinyapps::deployApp('GESample/')
jsonfile <- "data/Tweets.txt"
data <- fromJSON(sprintf("[%s]", paste(readLines(jsonfile), collapse=",")))
setwd("GESample/")
jsonfile <- "data/Tweets.txt"
data <- fromJSON(sprintf("[%s]", paste(readLines(jsonfile), collapse=",")))
data <- fromJSON(jsonfile)
setwd("GESample/")
jsonfile <- "data/Tweets_upd.txt"
data <- fromJSON(jsonfile)
data <- fromJSON(sprintf("[%s]", paste(readLines(jsonfile), collapse=",")))
class(data)
filenames <- list.files(path = "data/Tweets2/")
dataNew <- do.call("rbind", lapply(filenames, fromJSON))
dataNew <- do.call("rbind", lapply(filenames, fromJSON(filenames)))
files <- list.files("data/Tweets2/")
dataNew <- lapply(files,fromJSON)
files <- list.files("data/Tweets2")
dataNew <- lapply(files,fromJSON)
files <- list.files("data/Tweets2", full.names = TRUE)
dataNew <- lapply(files,fromJSON)
files <- list.files("data/Tweets2 copy/", full.names = TRUE)
dataNew <- lapply(files,fromJSON)
dataNew <- lapply(files,fromJSON)
dataNew <- fromJSON("data//Tweets2 copy/Tweet_0.txt")
dataNew <- fromJSON("data//Tweets2 copy/Tweet_0.txt")
dataNew <- fromJSON(sprintf("[%s]", paste(readLines("data/Tweets2 copy/Tweet_0.txt"), collapse=",")))
dataNew <- fromJSON("data/Tweets2/Tweet_0.txt")
dataNew <- fromJSON("data/Tweets2 copy/Tweet_10.txt")
dataNew <- jsonlite::fromJSON("data/Tweets2 copy/Tweet_10.txt")
dataNew <- jsonlite::fromJSON("data/Tweets2 copy/Tweet_10.txt", flatten=TRUE)
dataNew <- jsonlite::fromJSON(paste(readLines("data/Tweets2 copy/Tweet_10.txt")))
dataNew <- jsonlite::fromJSON(paste(readLines("data/Tweets2 copy/Tweet_10.txt")))
dataNew <- jsonlite::fromJSON(paste(readLines("data/Tweets2 copy/Tweet_10.txt")))
dataNew <- jsonlite::fromJSON(paste(readLines("data/Tweets2 copy/Tweet_10.txt")))
dataNew <- jsonlite::fromJSON(paste(readLines("data/Tweets2 copy/Tweet_0.txt")))
dataNew <- jsonlite::fromJSON(paste(readLines("data/Tweets2 copy/Tweet_0.txt")))
dataNew <- jsonlite::fromJSON("data/Tweets2 copy/Tweet_0.txt")
dataNew <- jsonlite::fromJSON("data/Tweets2 copy/Tweet_0.txt")
jsonlite::validate("data/Tweets2/Tweet_0.txt")
jsonlite::validate("data/Tweets2 copy//Tweet_0.txt")
dataNew <- jsonlite::fromJSON("data/Tweets2 copy/Tweet_0.txt")
